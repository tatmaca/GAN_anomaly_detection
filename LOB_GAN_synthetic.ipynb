{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbec1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LOB_GAN_synthetic_compare.py\n",
    "\n",
    "Use the trained generator (and discriminator) to produce synthetic LOB\n",
    "sequences for a few testing days, compare them to the real order books,\n",
    "and save plots. Now consistent with LOB_GAN_testing.py and uses the\n",
    "discriminator to pick abnormal vs normal days.\n",
    "\n",
    "Usage:\n",
    "    python3 LOB_GAN_synthetic_compare.py --stock 0005\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Models + Dataset\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.lay1 = nn.GRU(20, 40, num_layers=1, batch_first=True)\n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay3 = nn.GRU(40, 40, num_layers=1, batch_first=True)\n",
    "        self.lay4 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay5 = nn.GRU(\n",
    "            40, 19, num_layers=1, batch_first=True\n",
    "        )  # layer < 20 nodes to avoid repetition\n",
    "        self.lay6 = nn.Sequential(\n",
    "            nn.Linear(19, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay7 = nn.GRU(40, 20, num_layers=1, batch_first=True)\n",
    "        self.lay8 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 20)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y, _ = self.lay1(x)\n",
    "        z = self.lay2(y)\n",
    "        u, _ = self.lay3(z)\n",
    "        v = self.lay4(u)\n",
    "        w, _ = self.lay5(v)\n",
    "        o = self.lay6(w)\n",
    "        p, _ = self.lay7(o)\n",
    "        # q = self.lay8(p)\n",
    "        return p\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.lay1 = nn.GRU(20, 40, num_layers=2, batch_first=True)\n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay3 = nn.GRU(40, 40, num_layers=1, batch_first=True)\n",
    "        self.lay4 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay5 = nn.GRU(40, 40, num_layers=1, batch_first=True)\n",
    "        self.lay6 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 40)\n",
    "        )\n",
    "        self.lay7 = nn.GRU(40, 40, num_layers=1, batch_first=True)\n",
    "        self.lay8 = nn.Sequential(\n",
    "            nn.Linear(40, 40), nn.LeakyReLU(0.01), nn.Linear(40, 1)\n",
    "        )\n",
    "        self.drop = nn.Dropout(0.15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y, _ = self.lay1(x)\n",
    "        z = self.lay2(y)\n",
    "        v, _ = self.lay3(z)\n",
    "        u = self.lay4(v)\n",
    "        w, _ = self.lay5(u)\n",
    "        r = self.lay6(w)\n",
    "        s, _ = self.lay7(r)\n",
    "        t = self.lay8(s)\n",
    "        return torch.sigmoid(t[:, -1])\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Data prep (same as testing)\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "def prepareMinutelyData(df: pd.DataFrame, tradingDays: list) -> pd.DataFrame:\n",
    "    \"\"\"Same logic as in LOB_GAN_testing.py.\"\"\"\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    df[\"bfValue\"] = df[\"lastPx\"] * df[\"size\"]\n",
    "    df[\"bfValue\"] = df[\"bfValue\"].ffill()\n",
    "    df[\"cumValue\"] = df.groupby(\"date\")[\"bfValue\"].cumsum()\n",
    "    df = df[df[\"SP1\"] > 0]\n",
    "    df = df[df[\"BP1\"] > 0]\n",
    "    df = df[df[\"SP1\"] - df[\"BP1\"] > 0]\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        df[f\"SP{i}\"] = df[f\"SP{i}\"] / 100\n",
    "        df[f\"BP{i}\"] = df[f\"BP{i}\"] / 100\n",
    "        df[f\"SV{i}\"] = df[f\"SV{i}\"] * 1000\n",
    "        df[f\"BV{i}\"] = df[f\"BV{i}\"] * 1000\n",
    "\n",
    "    df[\"lastPx\"] = df[\"lastPx\"] / 100\n",
    "    df[\"size\"] = df[\"size\"] * 1000\n",
    "    df[\"volume\"] = df[\"volume\"] * 1000\n",
    "    df[\"lastPx\"] = df.groupby(\"date\")[\"lastPx\"].ffill()\n",
    "    df[\"size\"] = df.groupby(\"date\")[\"size\"].transform(lambda x: x.fillna(0))\n",
    "\n",
    "    df[\"value\"] = df.groupby(\"date\")[\"cumValue\"].diff()\n",
    "    df[\"value\"] = df[\"value\"].fillna(df[\"bfValue\"])\n",
    "    df.drop(columns=[\"bfValue\", \"cumValue\", \"value\"], inplace=True)\n",
    "\n",
    "    # build datetime index\n",
    "    df_DateTime = pd.to_datetime(\n",
    "        df.date.astype(str) + \" \" + df.time.astype(str), format=\"%Y-%m-%d %H%M%S%f\"\n",
    "    )\n",
    "    df[\"dt_index\"] = df_DateTime\n",
    "    df = df[~df.dt_index.duplicated(keep=\"last\")]\n",
    "\n",
    "    # bin to minutely\n",
    "    binSize = \"1min\"\n",
    "    df_minutely = df.groupby(\n",
    "        pd.Grouper(key=\"dt_index\", freq=binSize, closed=\"right\", label=\"right\")\n",
    "    ).last()\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        df_minutely.loc[:, f\"SP{i}\"] = df.groupby(\n",
    "            pd.Grouper(key=\"dt_index\", freq=binSize, closed=\"right\", label=\"right\")\n",
    "        )[f\"SP{i}\"].last()\n",
    "        df_minutely.loc[:, f\"BP{i}\"] = df.groupby(\n",
    "            pd.Grouper(key=\"dt_index\", freq=binSize, closed=\"right\", label=\"right\")\n",
    "        )[f\"BP{i}\"].last()\n",
    "        df_minutely.loc[:, f\"SV{i}\"] = df.groupby(\n",
    "            pd.Grouper(key=\"dt_index\", freq=binSize, closed=\"right\", label=\"right\")\n",
    "        )[f\"SV{i}\"].last()\n",
    "        df_minutely.loc[:, f\"BV{i}\"] = df.groupby(\n",
    "            pd.Grouper(key=\"dt_index\", freq=binSize, closed=\"right\", label=\"right\")\n",
    "        )[f\"BV{i}\"].last()\n",
    "\n",
    "    # session filter\n",
    "    df_minutely = df_minutely.between_time(\"09:00:00\", \"13:25:00\", inclusive=\"right\")\n",
    "    df_minutely[\"date\"] = df_minutely.index.date\n",
    "    df_minutely[\"ttime\"] = df_minutely.index.time\n",
    "    df_minutely[\"time\"].fillna(df_minutely[\"ttime\"], inplace=True)\n",
    "    df_minutely.drop(columns=[\"ttime\"], inplace=True)\n",
    "\n",
    "    df_minutely = df_minutely[df_minutely[\"date\"].astype(str).isin(tradingDays)]\n",
    "\n",
    "    return df_minutely\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "#  Main: generate & compare\n",
    "# -----------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e6637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --stock STOCK\n",
      "ipykernel_launcher.py: error: the following arguments are required: --stock\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--stock\", type=str, required=True, help=\"stock symbol\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    stock = args.stock\n",
    "    stockDataDir = \"data/\"\n",
    "\n",
    "    # columns to load from md files\n",
    "    cols = [\n",
    "        \"date\",\n",
    "        \"time\",\n",
    "        \"lastPx\",\n",
    "        \"size\",\n",
    "        \"volume\",\n",
    "        \"SP1\",\n",
    "        \"BP1\",\n",
    "        \"SV1\",\n",
    "        \"BV1\",\n",
    "        \"SP2\",\n",
    "        \"BP2\",\n",
    "        \"SV2\",\n",
    "        \"BV2\",\n",
    "        \"SP3\",\n",
    "        \"BP3\",\n",
    "        \"SV3\",\n",
    "        \"BV3\",\n",
    "        \"SP4\",\n",
    "        \"BP4\",\n",
    "        \"SV4\",\n",
    "        \"BV4\",\n",
    "        \"SP5\",\n",
    "        \"BP5\",\n",
    "        \"SV5\",\n",
    "        \"BV5\",\n",
    "    ]\n",
    "\n",
    "    # IMPORTANT:\n",
    "    # paste in the SAME tradingDays list you used in your training/testing scripts.\n",
    "    # For brevity, I don't repeat the full huge list here.\n",
    "    tradingDays = [\n",
    "        \"2023-10-02\",\n",
    "        \"2023-10-03\",\n",
    "        \"2023-10-04\",\n",
    "        \"2023-10-05\",\n",
    "        \"2023-10-06\",\n",
    "        \"2023-10-11\",\n",
    "        \"2023-10-12\",\n",
    "        \"2023-10-13\",\n",
    "        \"2023-10-16\",\n",
    "        \"2023-10-17\",\n",
    "        \"2023-10-18\",\n",
    "        \"2023-10-19\",\n",
    "        \"2023-10-20\",\n",
    "        \"2023-10-23\",\n",
    "        \"2023-10-24\",\n",
    "        \"2023-10-25\",\n",
    "        \"2023-10-26\",\n",
    "        \"2023-10-27\",\n",
    "        \"2023-10-30\",\n",
    "        \"2023-10-31\",\n",
    "        \"2023-11-01\",\n",
    "        \"2023-11-02\",\n",
    "        \"2023-11-03\",\n",
    "        \"2023-11-06\",\n",
    "        \"2023-11-07\",\n",
    "        \"2023-11-08\",\n",
    "        \"2023-11-09\",\n",
    "        \"2023-11-10\",\n",
    "        \"2023-11-13\",\n",
    "        \"2023-11-14\",\n",
    "        \"2023-11-15\",\n",
    "        \"2023-11-16\",\n",
    "        \"2023-11-17\",\n",
    "        \"2023-11-20\",\n",
    "        \"2023-11-21\",\n",
    "        \"2023-11-22\",\n",
    "        \"2023-11-23\",\n",
    "        \"2023-11-24\",\n",
    "        \"2023-11-27\",\n",
    "        \"2023-11-28\",\n",
    "        \"2023-11-29\",\n",
    "        \"2023-11-30\",\n",
    "        \"2023-12-01\",\n",
    "        \"2023-12-04\",\n",
    "        \"2023-12-05\",\n",
    "        \"2023-12-06\",\n",
    "        \"2023-12-07\",\n",
    "        \"2023-12-08\",\n",
    "        \"2023-12-11\",\n",
    "        \"2023-12-12\",\n",
    "        \"2023-12-13\",\n",
    "        \"2023-12-14\",\n",
    "        \"2023-12-15\",\n",
    "        \"2023-12-18\",\n",
    "        \"2023-12-19\",\n",
    "        \"2023-12-20\",\n",
    "        \"2023-12-21\",\n",
    "        \"2023-12-22\",\n",
    "        \"2023-12-25\",\n",
    "        \"2023-12-26\",\n",
    "        \"2023-12-27\",\n",
    "        \"2023-12-28\",\n",
    "        \"2023-12-29\",\n",
    "        \"2024-01-02\",\n",
    "        \"2024-01-03\",\n",
    "        \"2024-01-04\",\n",
    "        \"2024-01-05\",\n",
    "        \"2024-01-08\",\n",
    "        \"2024-01-09\",\n",
    "        \"2024-01-10\",\n",
    "        \"2024-01-11\",\n",
    "        \"2024-01-12\",\n",
    "        \"2024-01-15\",\n",
    "        \"2024-01-16\",\n",
    "        \"2024-01-17\",\n",
    "        \"2024-01-18\",\n",
    "        \"2024-01-19\",\n",
    "        \"2024-01-22\",\n",
    "        \"2024-01-23\",\n",
    "        \"2024-01-24\",\n",
    "        \"2024-01-25\",\n",
    "        \"2024-01-26\",\n",
    "        \"2024-01-29\",\n",
    "        \"2024-01-30\",\n",
    "        \"2024-01-31\",\n",
    "        \"2024-02-01\",\n",
    "        \"2024-02-02\",\n",
    "        \"2024-02-15\",\n",
    "        \"2024-02-16\",\n",
    "        \"2024-02-19\",\n",
    "        \"2024-02-20\",\n",
    "        \"2024-02-21\",\n",
    "        \"2024-02-22\",\n",
    "        \"2024-02-23\",\n",
    "        \"2024-02-26\",\n",
    "        \"2024-02-27\",\n",
    "        \"2024-02-29\",\n",
    "        \"2024-03-01\",\n",
    "        \"2024-03-04\",\n",
    "        \"2024-03-05\",\n",
    "        \"2024-03-06\",\n",
    "        \"2024-03-07\",\n",
    "        \"2024-03-08\",\n",
    "        \"2024-03-11\",\n",
    "        \"2024-03-12\",\n",
    "        \"2024-03-13\",\n",
    "        \"2024-03-14\",\n",
    "        \"2024-03-15\",\n",
    "        \"2024-03-18\",\n",
    "        \"2024-03-19\",\n",
    "        \"2024-03-20\",\n",
    "        \"2024-03-21\",\n",
    "        \"2024-03-22\",\n",
    "        \"2024-03-25\",\n",
    "        \"2024-03-26\",\n",
    "        \"2024-03-27\",\n",
    "        \"2024-03-28\",\n",
    "        \"2024-03-29\",\n",
    "        \"2024-04-01\",\n",
    "        \"2024-04-02\",\n",
    "        \"2024-04-03\",\n",
    "        \"2024-04-08\",\n",
    "        \"2024-04-09\",\n",
    "        \"2024-04-10\",\n",
    "        \"2024-04-11\",\n",
    "        \"2024-04-12\",\n",
    "        \"2024-04-15\",\n",
    "        \"2024-04-16\",\n",
    "        \"2024-04-17\",\n",
    "        \"2024-04-18\",\n",
    "        \"2024-04-19\",\n",
    "        \"2024-04-22\",\n",
    "        \"2024-04-23\",\n",
    "        \"2024-04-24\",\n",
    "        \"2024-04-25\",\n",
    "        \"2024-04-26\",\n",
    "        \"2024-04-29\",\n",
    "        \"2024-04-30\",\n",
    "        \"2024-05-02\",\n",
    "        \"2024-05-03\",\n",
    "        \"2024-05-06\",\n",
    "        \"2024-05-07\",\n",
    "        \"2024-05-08\",\n",
    "        \"2024-05-09\",\n",
    "        \"2024-05-10\",\n",
    "        \"2024-05-13\",\n",
    "        \"2024-05-14\",\n",
    "        \"2024-05-15\",\n",
    "        \"2024-05-16\",\n",
    "        \"2024-05-17\",\n",
    "        \"2024-05-20\",\n",
    "        \"2024-05-21\",\n",
    "        \"2024-05-22\",\n",
    "        \"2024-05-23\",\n",
    "        \"2024-05-24\",\n",
    "        \"2024-05-27\",\n",
    "        \"2024-05-28\",\n",
    "        \"2024-05-29\",\n",
    "        \"2024-05-30\",\n",
    "        \"2024-05-31\",\n",
    "        \"2024-06-03\",\n",
    "        \"2024-06-04\",\n",
    "        \"2024-06-05\",\n",
    "        \"2024-06-06\",\n",
    "        \"2024-06-07\",\n",
    "        \"2024-06-11\",\n",
    "        \"2024-06-12\",\n",
    "        \"2024-06-13\",\n",
    "        \"2024-06-14\",\n",
    "        \"2024-06-17\",\n",
    "        \"2024-06-18\",\n",
    "        \"2024-06-19\",\n",
    "        \"2024-06-20\",\n",
    "        \"2024-06-21\",\n",
    "        \"2024-06-24\",\n",
    "        \"2024-06-25\",\n",
    "        \"2024-06-26\",\n",
    "        \"2024-06-27\",\n",
    "        \"2024-06-28\",\n",
    "        \"2024-07-01\",\n",
    "        \"2024-07-02\",\n",
    "        \"2024-07-03\",\n",
    "        \"2024-07-04\",\n",
    "        \"2024-07-05\",\n",
    "        \"2024-07-08\",\n",
    "        \"2024-07-09\",\n",
    "        \"2024-07-10\",\n",
    "        \"2024-07-11\",\n",
    "        \"2024-07-12\",\n",
    "        \"2024-07-15\",\n",
    "        \"2024-07-16\",\n",
    "        \"2024-07-17\",\n",
    "        \"2024-07-18\",\n",
    "        \"2024-07-19\",\n",
    "        \"2024-07-22\",\n",
    "        \"2024-07-23\",\n",
    "        \"2024-07-26\",\n",
    "        \"2024-07-29\",\n",
    "        \"2024-07-30\",\n",
    "        \"2024-07-31\",\n",
    "        \"2024-08-01\",\n",
    "        \"2024-08-02\",\n",
    "        \"2024-08-05\",\n",
    "        \"2024-08-06\",\n",
    "        \"2024-08-07\",\n",
    "        \"2024-08-08\",\n",
    "        \"2024-08-09\",\n",
    "        \"2024-08-12\",\n",
    "        \"2024-08-13\",\n",
    "        \"2024-08-14\",\n",
    "        \"2024-08-15\",\n",
    "        \"2024-08-16\",\n",
    "        \"2024-08-19\",\n",
    "        \"2024-08-20\",\n",
    "        \"2024-08-21\",\n",
    "        \"2024-08-22\",\n",
    "        \"2024-08-23\",\n",
    "        \"2024-08-26\",\n",
    "        \"2024-08-27\",\n",
    "        \"2024-08-28\",\n",
    "        \"2024-08-29\",\n",
    "        \"2024-08-30\",\n",
    "        \"2024-09-02\",\n",
    "        \"2024-09-03\",\n",
    "        \"2024-09-04\",\n",
    "        \"2024-09-05\",\n",
    "        \"2024-09-06\",\n",
    "        \"2024-09-09\",\n",
    "        \"2024-09-10\",\n",
    "        \"2024-09-11\",\n",
    "        \"2024-09-12\",\n",
    "        \"2024-09-13\",\n",
    "        \"2024-09-16\",\n",
    "        \"2024-09-18\",\n",
    "        \"2024-09-19\",\n",
    "        \"2024-09-20\",\n",
    "        \"2024-09-23\",\n",
    "        \"2024-09-24\",\n",
    "        \"2024-09-25\",\n",
    "        \"2024-09-26\",\n",
    "        \"2024-09-27\",\n",
    "        \"2024-09-30\",\n",
    "        \"2024-10-01\",\n",
    "        \"2024-10-02\",\n",
    "        \"2024-10-03\",\n",
    "        \"2024-10-04\",\n",
    "        \"2024-10-07\",\n",
    "        \"2024-10-08\",\n",
    "        \"2024-10-09\",\n",
    "        \"2024-10-11\",\n",
    "        \"2024-10-14\",\n",
    "        \"2024-10-15\",\n",
    "        \"2024-10-16\",\n",
    "        \"2024-10-17\",\n",
    "        \"2024-10-18\",\n",
    "        \"2024-10-21\",\n",
    "        \"2024-10-22\",\n",
    "        \"2024-10-23\",\n",
    "        \"2024-10-24\",\n",
    "        \"2024-10-25\",\n",
    "        \"2024-10-28\",\n",
    "        \"2024-10-29\",\n",
    "        \"2024-10-30\",\n",
    "        \"2024-10-31\",\n",
    "        \"2024-11-01\",\n",
    "        \"2024-11-04\",\n",
    "        \"2024-11-05\",\n",
    "        \"2024-11-06\",\n",
    "        \"2024-11-07\",\n",
    "        \"2024-11-08\",\n",
    "        \"2024-11-11\",\n",
    "        \"2024-11-12\",\n",
    "        \"2024-11-13\",\n",
    "        \"2024-11-14\",\n",
    "        \"2024-11-15\",\n",
    "        \"2024-11-18\",\n",
    "        \"2024-11-19\",\n",
    "        \"2024-11-20\",\n",
    "        \"2024-11-21\",\n",
    "        \"2024-11-22\",\n",
    "        \"2024-11-25\",\n",
    "        \"2024-11-26\",\n",
    "        \"2024-11-27\",\n",
    "        \"2024-11-28\",\n",
    "        \"2024-11-29\",\n",
    "        \"2024-12-02\",\n",
    "        \"2024-12-03\",\n",
    "        \"2024-12-04\",\n",
    "        \"2024-12-05\",\n",
    "        \"2024-12-06\",\n",
    "        \"2024-12-09\",\n",
    "        \"2024-12-10\",\n",
    "        \"2024-12-11\",\n",
    "        \"2024-12-12\",\n",
    "        \"2024-12-13\",\n",
    "        \"2024-12-16\",\n",
    "        \"2024-12-17\",\n",
    "        \"2024-12-18\",\n",
    "        \"2024-12-19\",\n",
    "        \"2024-12-20\",\n",
    "        \"2024-12-23\",\n",
    "        \"2024-12-24\",\n",
    "        \"2024-12-25\",\n",
    "        \"2024-12-26\",\n",
    "        \"2024-12-27\",\n",
    "        \"2024-12-30\",\n",
    "        \"2024-12-31\",\n",
    "    ]  # if you expose it there\n",
    "    # Or, alternatively, manually define tradingDays = [...] here.\n",
    "\n",
    "    print(f\"Loading raw testing data for {stock}...\")\n",
    "\n",
    "    # testing months: Jan–Mar 2024 (same as your testing file)\n",
    "    file1Path = os.path.join(stockDataDir, f\"{stock}_md_202401_202401.csv.gz\")\n",
    "    file2Path = os.path.join(stockDataDir, f\"{stock}_md_202402_202402.csv.gz\")\n",
    "    file3Path = os.path.join(stockDataDir, f\"{stock}_md_202403_202403.csv.gz\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for path in [file1Path, file2Path, file3Path]:\n",
    "        if os.path.exists(path):\n",
    "            df = pd.concat([df, pd.read_csv(path, compression=\"gzip\", usecols=cols)])\n",
    "            print(f\"Loaded {path}\")\n",
    "        else:\n",
    "            print(f\"Skipping missing snapshots: {path}\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"No md data for {stock}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # minute-level data\n",
    "    minutelyData = prepareMinutelyData(df, tradingDays)\n",
    "    print(\"Minutely data generated.\")\n",
    "\n",
    "    # build daily sequences as in training/testing\n",
    "    projdata = []\n",
    "    columns = [\n",
    "        \"date\",\n",
    "        \"time\",\n",
    "        \"lastPx\",\n",
    "        \"size\",\n",
    "        \"volume\",\n",
    "        \"SP5\",\n",
    "        \"SP4\",\n",
    "        \"SP3\",\n",
    "        \"SP2\",\n",
    "        \"SP1\",\n",
    "        \"BP1\",\n",
    "        \"BP2\",\n",
    "        \"BP3\",\n",
    "        \"BP4\",\n",
    "        \"BP5\",\n",
    "        \"SV5\",\n",
    "        \"SV4\",\n",
    "        \"SV3\",\n",
    "        \"SV2\",\n",
    "        \"SV1\",\n",
    "        \"BV1\",\n",
    "        \"BV2\",\n",
    "        \"BV3\",\n",
    "        \"BV4\",\n",
    "        \"BV5\",\n",
    "    ]\n",
    "\n",
    "    minutelyData = minutelyData.reset_index()  # dt_index becomes a column\n",
    "    md = minutelyData.set_index(\"dt_index\")\n",
    "\n",
    "    seq_dates = []  # for reference (one per full day)\n",
    "\n",
    "    for date, df_day in md.groupby(\"date\"):\n",
    "        if df_day.shape[0] == 265:\n",
    "            projdata.append(df_day[columns].values)\n",
    "            seq_dates.append(date)\n",
    "\n",
    "    projdata = np.array(projdata)\n",
    "    seq_dates = np.array(seq_dates)\n",
    "\n",
    "    if projdata.shape[0] == 0:\n",
    "        print(\"No days with exactly 265 minutes. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # normalization (same as training/testing)\n",
    "    X = projdata[:, :, 5:].astype(float)  # take 20 LOB features\n",
    "\n",
    "    X[:, :, -10:] = np.log(1 + X[:, :, -10:])\n",
    "    X_mean = X.mean(axis=1)\n",
    "    X_std = X.std(axis=1)\n",
    "\n",
    "    X = np.transpose((np.transpose(X, (1, 0, 2)) - X_mean) / (2 * X_std), (1, 0, 2))\n",
    "    X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "    # dataset & generator\n",
    "    set_seed(307)\n",
    "    dataset = MyDataset(torch.tensor(X, dtype=torch.float32))\n",
    "\n",
    "    model_dir = f\"data_{stock}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    gen_path = os.path.join(model_dir, f\"{stock}_generator1.pth\")\n",
    "\n",
    "    if not os.path.exists(gen_path):\n",
    "        print(f\"Generator file not found: {gen_path}\")\n",
    "        return\n",
    "\n",
    "    generator = torch.load(gen_path, weights_only=False)\n",
    "    generator.eval()\n",
    "    print(f\"Loaded generator from {gen_path}\")\n",
    "\n",
    "    # pick a few example days\n",
    "    n_days = len(dataset)\n",
    "    sample_indices = sorted(set([0, min(5, n_days - 1), min(10, n_days - 1)]))\n",
    "\n",
    "    feature_cols = [\n",
    "        \"SP5\",\n",
    "        \"SP4\",\n",
    "        \"SP3\",\n",
    "        \"SP2\",\n",
    "        \"SP1\",\n",
    "        \"BP1\",\n",
    "        \"BP2\",\n",
    "        \"BP3\",\n",
    "        \"BP4\",\n",
    "        \"BP5\",\n",
    "        \"SV5\",\n",
    "        \"SV4\",\n",
    "        \"SV3\",\n",
    "        \"SV2\",\n",
    "        \"SV1\",\n",
    "        \"BV1\",\n",
    "        \"BV2\",\n",
    "        \"BV3\",\n",
    "        \"BV4\",\n",
    "        \"BV5\",\n",
    "    ]\n",
    "\n",
    "    print(\"Generating synthetic sequences and saving comparison plots...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in sample_indices:\n",
    "            real_seq_norm = dataset[idx].unsqueeze(0)  # (1, 265, 20)\n",
    "            gen_seq_norm = generator(real_seq_norm)    # (1, 265, 20)\n",
    "\n",
    "            real_seq_norm = real_seq_norm.numpy()[0]   # (265, 20)\n",
    "            gen_seq_norm = gen_seq_norm.numpy()[0]     # (265, 20)\n",
    "\n",
    "            mu = X_mean[idx]       # (20,)\n",
    "            sigma = X_std[idx]     # (20,)\n",
    "\n",
    "            real_seq = real_seq_norm * (2 * sigma) + mu\n",
    "            gen_seq = gen_seq_norm * (2 * sigma) + mu\n",
    "\n",
    "            df_real = pd.DataFrame(real_seq, columns=feature_cols)\n",
    "            df_gen = pd.DataFrame(gen_seq, columns=feature_cols)\n",
    "\n",
    "            df_real[\"minute\"] = np.arange(df_real.shape[0])\n",
    "            df_gen[\"minute\"] = np.arange(df_gen.shape[0])\n",
    "\n",
    "            day_label = str(seq_dates[idx])\n",
    "\n",
    "            # ---- Plot 1: best bid/ask intraday ----\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(df_real[\"minute\"], df_real[\"BP1\"], label=\"Real BP1\", alpha=0.8)\n",
    "            plt.plot(df_real[\"minute\"], df_real[\"SP1\"], label=\"Real SP1\", alpha=0.8)\n",
    "            plt.plot(df_gen[\"minute\"], df_gen[\"BP1\"], \"--\", label=\"Synthetic BP1\", alpha=0.8)\n",
    "            plt.plot(df_gen[\"minute\"], df_gen[\"SP1\"], \"--\", label=\"Synthetic SP1\", alpha=0.8)\n",
    "            plt.title(f\"{stock} – {day_label}: Best bid/ask over the day\")\n",
    "            plt.xlabel(\"Minute of day\")\n",
    "            plt.ylabel(\"Price\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(model_dir, f\"{stock}_day{idx}_best_prices.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # ---- Plot 2: spread intraday ----\n",
    "            real_spread = df_real[\"SP1\"] - df_real[\"BP1\"]\n",
    "            gen_spread = df_gen[\"SP1\"] - df_gen[\"BP1\"]\n",
    "\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(df_real[\"minute\"], real_spread, label=\"Real spread\", alpha=0.8)\n",
    "            plt.plot(df_gen[\"minute\"], gen_spread, \"--\", label=\"Synthetic spread\", alpha=0.8)\n",
    "            plt.title(f\"{stock} – {day_label}: Bid–ask spread over the day\")\n",
    "            plt.xlabel(\"Minute of day\")\n",
    "            plt.ylabel(\"Spread\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(model_dir, f\"{stock}_day{idx}_spread.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            # ---- Plot 3: average depth profile ----\n",
    "            real_bid_depth = df_real[[\"BV1\", \"BV2\", \"BV3\", \"BV4\", \"BV5\"]].mean(axis=0)\n",
    "            real_ask_depth = df_real[[\"SV1\", \"SV2\", \"SV3\", \"SV4\", \"SV5\"]].mean(axis=0)\n",
    "            gen_bid_depth = df_gen[[\"BV1\", \"BV2\", \"BV3\", \"BV4\", \"BV5\"]].mean(axis=0)\n",
    "            gen_ask_depth = df_gen[[\"SV1\", \"SV2\", \"SV3\", \"SV4\", \"SV5\"]].mean(axis=0)\n",
    "\n",
    "            levels = np.arange(1, 6)\n",
    "\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.plot(levels, real_bid_depth.values, \"-o\", label=\"Real bid depth\")\n",
    "            plt.plot(levels, gen_bid_depth.values, \"--o\", label=\"Synthetic bid depth\")\n",
    "            plt.plot(levels, real_ask_depth.values, \"-s\", label=\"Real ask depth\")\n",
    "            plt.plot(levels, gen_ask_depth.values, \"--s\", label=\"Synthetic ask depth\")\n",
    "            plt.xticks(levels)\n",
    "            plt.xlabel(\"Level (1 = top of book)\")\n",
    "            plt.ylabel(\"Average depth\")\n",
    "            plt.title(f\"{stock} – {day_label}: Average depth profile\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(model_dir, f\"{stock}_day{idx}_depth_profile.png\"), dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Saved plots for day index {idx} ({day_label})\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
